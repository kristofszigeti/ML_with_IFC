"""
Ok√©, akkor most r√°engedj√ºk az IsolationForest-et a val√≥di bolt_count feature-re, √©s visszacsatoljuk az eredm√©nyt a Plate-ekhez.

Most egy √∫j scriptet csin√°lunk, ami √ñNMAG√ÅBAN elint√©zi:

beolvas√°s: plate_features.csv

numerikus feature k√©pz√©s: bolt_count

modell tan√≠t√°s: IsolationForest

eredm√©nyek vissza√≠r√°sa Plate-szinten: predictions_plates.csv

Nem fogunk most a features.csv-re t√°maszkodni, hogy ne legyen elcs√∫sz√°s a sz≈±r√©sek miatt.

üö© Script: src/train_plate_anomaly.py
Feladata r√∂viden

plate_features.csv ‚Üí kivessz√ºk bel≈ële a bolt_count-ot

kisz≈±rj√ºk a rossz sorokat (NaN, nem sz√°m)

IsolationForest-et tan√≠tunk

vissza√≠rjuk az eredm√©nyeket:
"""

import pandas as pd                           # T√°bl√°zatos adatokhoz
from pathlib import Path                      # El√©r√©si utak kezel√©s√©hez
from sklearn.ensemble import IsolationForest  # Anom√°liadetekt√°l√≥ modell
from joblib import dump                       # Modell ment√©s√©hez .pkl form√°ban

# 1) Bemeneti √©s kimeneti √∫tvonalak
in_path = Path("../../data/output/csv_dataframe/plate_features.csv")          # Plate + bolt_count adat
out_path = Path("../../data/output/csv_dataframe_flagged/flagged_plates.csv")     # Ide mentj√ºk az eredm√©nyeket
model_path = Path("../../data/models/isoforest_boltcount.pkl")     # Ide mentj√ºk a tanult modellt

# 2) Kimeneti mapp√°k biztos√≠t√°sa
out_path.parent.mkdir(parents=True, exist_ok=True)   # processed mappa l√©trehoz√°sa, ha nincs
model_path.parent.mkdir(parents=True, exist_ok=True) # models mappa l√©trehoz√°sa, ha nincs

# 3) Plate-feature t√°bla beolvas√°sa
df = pd.read_csv(in_path)       # PlateGlobalId, Assembly..., bolt_count oszlopokkal

# 4) Numerikus feature (bolt_count) kiv√©tele
X = df[["bolt_count"]].copy()   # Csak a bolt_count oszlopot haszn√°ljuk bemenetk√©nt

# 5) Biztos√≠tjuk, hogy bolt_count numerikus legyen
X["bolt_count"] = pd.to_numeric(X["bolt_count"], errors="coerce")  # Hib√°s √©rt√©kek ‚Üí NaN

# 6) NaN √©rt√©kek kisz≈±r√©se
mask = X["bolt_count"].notna()          # True ott, ahol √©rv√©nyes a bolt_count
X_used = X.loc[mask].reset_index(drop=True)   # Csak a haszn√°lhat√≥ sorok a modellnek
df_used = df.loc[mask].reset_index(drop=True) # Ugyanezek a plate sorok metaadatokkal

# 7) R√∂vid riport a tan√≠t√≥adatr√≥l (dokument√°ci√≥hoz j√≥l j√∂n)
print("√ñsszes plate sor        :", len(df))
print("Felhaszn√°lt plate sorok :", len(df_used))
print("bolt_count statisztika a tan√≠t√≥halmazon:")
print(X_used["bolt_count"].describe())

# 8) IsolationForest modell p√©ld√°nyos√≠t√°sa
model = IsolationForest(
    n_estimators=200,     # F√°k sz√°ma az erd≈ëben (stabilit√°s)
    contamination=0.05,   # Becsl√©s: kb. 5% anom√°lia v√°rhat√≥
    random_state=42,      # Reproduk√°lhat√≥s√°g (ugyanaz az eredm√©ny fut√°sr√≥l fut√°sra)
)

# 9) Modell tan√≠t√°sa a bolt_count adatra
model.fit(X_used)   # A modell megtanulja, mi sz√°m√≠t "norm√°lis" boltsz√°mnak

# 10) Anom√°lia c√≠mk√©k √©s pontsz√°mok sz√°m√≠t√°sa
labels = model.predict(X_used)            # +1 = norm√°l, -1 = anom√°lia
scores = model.decision_function(X_used)  # Min√©l kisebb, ann√°l ink√°bb anom√°lia

# 11) Eredm√©nyek visszacsatol√°sa a plate metaadatokhoz
df_used["anomaly_score"] = scores        # Folytonos anom√°lia-pontsz√°m
df_used["anomaly_label"] = labels        # Diszkr√©t c√≠mke: +1 / -1

# 12) Eredm√©nyek ment√©se CSV-be
df_used.to_csv(out_path, index=False)    # Minden plate sor + boltsz√°m + anom√°lia eredm√©ny

# 13) Modell ment√©se .pkl f√°jlba (k√©s≈ëbbi UI / √∫jrafuttat√°s miatt)
dump(model, model_path)

print(f"\n‚úÖ Predictions saved to: {out_path}")
print(f"‚úÖ Model saved to: {model_path}")
print("\nMinta eredm√©nyek:")
print(df_used.head())
